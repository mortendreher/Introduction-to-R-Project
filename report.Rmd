---
title: "Introduction To R And Shiny Apps - Project report"
author: "Melita Coneva, Lars Andersen, Morten Dreher"
date: "19/07/2021"
output:
  pdf_document: 
    toc: true
    toc_depth: 2
  html_document: 
    toc: true
    toc_depth: 2
  fontsize: 12pt
  spacing: 1.15
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.pos = "!H", echo = TRUE)
library(knitr)
# knitr::opts_chunk$set(echo = TRUE)
```

\pagebreak


# Introduction

## Liver cancer

### Overview

The liver is the central metabolism organ of the human body.  
It is located in the upper right side and protected by the lower ribs.
With a weight of approximately 1500 grams, it is the largest gland of the human anatomy.  
Besides metabolism, the liver is also responsible for producing a variety of coagulation factors and hormones.  
The organ is also essential for removing external substances like alcohol and medications from the blood stream.   
For 2020, the WHO estimated the number of new cases of liver cancer (ICD C22) to be 905 677 (CI:[884695-927157]).  
According to the WHO, liver cancer caused 830 000 deaths worldwide in 2020 and is therefore considered the type of cancer with the third highest amount of cancer related deaths, a number only exceeded by lung cancer (1.8 million deaths worldwide), which takes the top spot in that statistic and colorectal cancer (935 000 deaths worldwide), which is ranked second for cancer related deaths.

### Epidemiology

In most sources, liver cancer prevalence, incidence and mortality for men is about 2-3 times as high as it is for women.
WHO data estimates that in 2020, 632 000 men and 273 000 women were diagnosed with liver cancer and that in the same year, 578 000 men and 253 000 women in association with liver cancer. For men, liver cancer mortality is only surpassed by lung cancer mortality.
For women on the other hand, liver cancer only takes sixth place in terms of total deaths, with sex-specific tumours like breast and uterus cancer accounting for more deaths.  
For Germany, the most recent data available describes new cases and mortality in 2017. In this year, 6040 men and 2903 women were diagnosed with liver cancer and 5213 men and 2697 women died in association with liver cancer.

### Risk factors 

Chronic hepatitis B or hepatitis C infections greatly increase the risk of developing liver cancer.  
Cirrhosis, an irreversible process in which healthy liver tissue is replaced by scar tissue, thus losing its functions, is also a prominent risk factor for liver cancer.  
Excessive alcohol consumption, obesity, diabetes and nonalcoholic fatty liver disease are also associated with an increased risk for liver cancer.

### Symptoms

There are multiple symptoms, but the one that displays the liver function most is jaundice, also known as icterus, in which your skin and especially eyes turn yellow.  
Other symptoms as a loss of appetite, feeling generally unwell as well as having a loss of energy and tiredness are widely considered as symptoms of cancer of any type.

### Diagnosis

The diagnostic process is the same as for most cancer types. Typically, there are blood tests to look for tumour markers as well as a biopsy, in that case of liver cells.  
Other possible diagnostic options are PET scans, CTA or MRI scans.

### Treatment

* Surgery
* Ablation
* Embolization Therapy
* Radiation Therapy
* Targeted Drug Therapy
* Immunotherapy
* Chemotheraphy

### Prevention

As HBV and HCV infections are major risk factors for the development of liver cancer, taking precautions against these viruses can help prevent the disease.  
Protection against hepatitis B can be obtained by a vaccine which is recommended for children and adults at risk in many countries including Germany, the US and the UK.
Hepatitis C is transmitted parenterally and sexually, therefore prevention includes only using clean, disinfected needles and syringes as well as being aware of the health status of sexual partners.  
In the case that an infection with HBV or HCV could not be prevented, treatments reducing liver cancer risk despite these afflictions are available.  
In a 2007 meta-analysis, increased coffee consumption was found to be associated to a lower risk of liver cancer.  
Reducing alcohol consumption and keeping a healthy weight can also help reduce liver cancer risk.

# Our plan

## Planned Dataset Manipulation

Our first step was to gather important information that we needed to adjust the dataset for liver cancer. As weight and height were already given, we decided to calculate BMI.
To better quantify smoking behaviour, we thought of adding and calculating the variable packyears. For this variable, we would require the number of years a person smoked as well as the number of cigarettes they smoke each day. We planned on simulating both of these variables.  
Another important risk factor that has been linked to an increased chance of liver cancer is alcohol abuse. To be able to measure alcohol consumption, we planned on simulating the variable alcohol consumption in grams per day.
A leading risk factor for liver cancer is chronic hepatitis B (HBV) or chronic hepatitis C (HCV). For these two, we planned on adding dichotomous variables. Another dichotomous variable we decided to add was diabetes. 
For the missing values of cholesterol, we thought of imputing the data with either KNN or BMI-grouped mean (see Dataset Manipulation).
To enhance the dataset, we decided to round multiple variables including cholesterol, weight and height. Generally, weight appears with one rounded decimal point and since the height was already given in centimeters, we did not need any additional digits.
After a closer look at the data, we realized that two variables, smoking and gender, were identical. This would mean that we only have smoking women and non-smoking men. To get some variation, our idea was to modify one of these variables.
We also wanted to rename variables smoking to smoker and gender to sex.


## General Plan for the App

Our core idea about the app was that it should be as interactive as possible while still performing well in terms of reaction time. Users should be able to select variables for plots and tables. 

## Graphs and tables

We decided to add multiple graphs to our Shiny App. To show the relationship between two numerical variables, we chose a scatter plot. The idea was that the user would be able to choose variables for x and y axis as well as select a grouping variable.
Furthermore, we wanted to add a box plot for continuous variables, that the user can interactively customise by selecting the displayed variable and group by a categorical variable.
To summarize discrete or continuous variables, we wanted to implement a histogram. Just like with the other plots, the user should also be able to choose a variable.
A last graph that we wanted to add was a pie chart in order to show percentages of categorical variables.
In terms of tables, we decided to create a table displaying important statistical parameters such as minimum, quartiles, mean and maximum for continuous variables.
We also planned on adding a table allowing a user to determine confidence intervals for a user-chosen alpha.
Another table we wanted to implement was a table calculating risks, odds and related estimates for two dichotomous variables. 

## Additional ideas

As some of our team members had experience with Time Series Analysis, we also wanted to simulate certain parameters for multiple points in time and implement some form of Survival Analysis.  
Another thought was considering additional statistical effects such as confounding in our app.


# Dataset manipulation

This section concerns itself with how our team adapted the _cancer_data.csv_ file for our specific needs and how we addressed missing values.

## General changes

Metric variables with digits were rounded to decimal points depending on their values. As height was given in centimeters, we rounded it to full integers. Weight, given in kilograms, was rounded to one decimal point. Cholesterol values were rounded to two digits.  
Gender was renamed to sex and smoking was renamed to smoker.

## Added variables

To adjust the dataset for liver cancer, we added a few variables.  
As both patient height and weight were available, we computed Body Mass Index (BMI) for all patients with one decimal point.
When looking at smoking behaviour, packyears is a more powerful measure than the given dichotomous variable indicating whether or not a person is currently smoking. Packyears are calculated as the product of years that a person has been smoking for and the number of cigarette packs they smoke each day. I.e. a person smoking one pack of cigarettes a day for 5 years would have 5 packyears. To compute packyears, we added a variable _cigs_per_day_ describing how many (if any) cigarettes patients smoked each day. This variable can only be realistically measured by asking the patient about it. In such surveys, humans tend to round numbers, which is why we decided that the cigarettes per day variable should only contain uniformly randomly generated multiples of ten ranging from 0 (for non-smokers) to 60. 
With 20 cigarettes per pack, this means that we have a maximum of 3 packs per day smoked.  
The more difficult part was modeling how long patients had been smoking for. According to the US Centers for Disease Control and Prevention, 9 out of 10 smoking adults first tried smoking by age 18 and 99% first tried smoking by age 26.  
Therefore, we determined that all smoking patients started between ages 16 and 26 or age 16 and the smallest age observed in our study, should it be smaller than 26. The smallest age observed in the data coincided to be precisely 26. In this interval, uniformly random values were generated.  
Packyears were then calculated as: 
$$
packyears=\frac{cigs\_per\_day}{20} \cdot (age-age_{started})
$$
Another variable we considered to be closely related to liver cancer was alcohol consumption. Alcohol abuse can lead to fatty liver disease or liver cirrhosis and thus increase risk for liver cancer. To generate these values, we decided to use a positively skewed distribution in order to simulate rather low alcohol consumption for most patients while still allowing for outliers with high alcohol consumption.
We multiplied random values of a chi-squared distribution with 4 degrees of freedom by 25 to generate values for alcohol consumption.  
Compared to the general population, the generated alcohol consumption values were very high, however we justified these high values by the fact that our sample consists exclusively of patients with liver cancer, a disease for which excessive alcohol consumption is a major risk factor.  
Alcohol consumption in grams per day was saved with the precision of one decimal point.  
The distribution used to simulate alcohol consumption in grams per day:

![](img/alc_dist.png){width=50%}

As advanced stages of liver cancer are associated with icterus, a yellowish pigmentation of the skin caused by an increase in blood bilirubin levels, we also included bilirubin in our dataset. 
We decided to model bilirubin in dependency of other variables in the dataset, namely cholesterol, tumour size, alcohol consumption and packyears as we saw those variables indicative of liver function. The bilirubin variable in our dataset has two digits.


## Missing values 

In the original data, three cholesterol observations were missing. In order to find accurate replacements, we compared results of BMI-grouped means and kNN imputation.

### BMI-grouped means

For this approach, we added a new variable describing BMI groups. Observations were assigned to one of four classes based on their BMI as follows: 

BMI class | BMI
-- | -- 
1 | $BMI <22$
2 | $22\leq BMI <24$
3 | $24\leq BMI < 26$
4 | $BMI \geq 26$

For observations with missing cholesterol values, we determined their BMI group and imputed the arithmetic mean for cholesterol in that group (over all non-missing observations).
The motivation behind this was that patients with similar BMIs were assumed to have similar cholesterol values as well.  
However, this approach was discarded later on as BMI groups were large and we feared that mean imputation would be inaccurate and would underestimate true variance for such large group sizes. 

### kNN imputation

As our concerns with the accuracy of the aforementioned BMI-grouped means approach grew, we started looking for alternative imputation methods based on fewer observations. Our goal was to replace missing values by using similar observations in the hope that they would also be similar for cholesterol.
A very common and effective way to replace missing data based on similar observations is the kNN (k-nearest neighbours) method.  
This algorithm determines the _k_ closest entries to an observation with missing values and imputes the mean of those nearest neighbours.  
When it comes to choosing _k_, there is no universally optimal solution. Different values for _k_ might be optimal for different datasets.
In more sophisticated imputations, the existing data can be used to calculate the optimal value for _k_. However, as data imputation was not the main focus of this project, we simply chose _k_ so that neighbour values were sufficiently similar. Comparing standard deviations of cholesterol for _k_=3,5,7,9 showed that values were most similar for _k_=3, so this was chosen as the number of neighbours to be considered.  
For our kNN approach, we decided that as few as possible variables should be used and that those variables should have a substantial association to cholesterol as to not reduce model accuracy due to noise in the data. Furthermore, we realised that implementing weighting of variables could prove useful.  
The variables we used to find nearest neighbours for cholesterol were:

 * sex (weight=0.25): distributions of cholesterol differed between sexes
 * age (weight=1): a linear association between age and cholesterol was found in the data
 * bmi (weight=1.25): the data showed an association between bmi and cholesterol. bmi was assigned additional weight as higher bmi is associated with higher levels of cholesterol in literature
 * size (weight=1): a linear association between size and cholesterol was present in the data

Our implementation of the kNN algorithm was split into two functions, one computing distances and a second one returning the _k_ nearest neighbours based on the distances calculated using the first function. 

```{r knn, eval=FALSE}
#' Compute distances from one node in a data frame to all other nodes
#' @param df Data frame
#' @param id Row number of the reference node
#' @param vars A vector specifying variables to be considered (by columns)
#' @param weights A vector specifying weights for the variables
#' @return The distances of specified node to all other nodes
#' @examples
#' distances(df, id = 3, vars = c(1, 2, 3), weights = c(1.25, 2, 1.5))
distances <- function(df, id, vars, weights = rep.int(1, length(vars))) {
  distance_to_id <- numeric(length(df[, 1]))
  for (v in vars) {
    for (i in (1:length(distance_to_id))) {
      rng <- range(df[, v])
      distance_to_id[i] <- distance_to_id[i] +
        (abs(df[i, v] - df[id, v]) / (rng[2] - rng[1])) * weights[which(vars == v)]
    }
  }
  return(distance_to_id)
}

#' Return IDs of k nearest neighbours for a specified node
#' @param df Data frame
#' @param id Row number of the reference node
#' @param vars A vector specifying variables to be considered (by columns)
#' @param k Number of nearest neighbours to be found
#' @param weights A vector specifying weights for the variables
#' @examples
#' knn(df, id = 3, vars = c(1, 2, 3), k = 3, weights = c(1.25, 2, 1.5))
knn <- function(df, id, vars, k, weights = rep.int(1, length(vars))) {
  distances_to_id <- distances(df, id, vars, weights)
  df_with_distances <- data.frame(cbind(df, distances_to_id), ordered_id = (1:length(distances_to_id)))
  df_with_distances <- filter(df_with_distances, ordered_id != id)
  df_with_distances <- arrange(df_with_distances, df_with_distances$distances_to_id)
  return(df_with_distances$ordered_id[1:k])
}
```

Imputed values computed from our kNN method are listed below:

ID of NA | Chol neighbour 1 (distance) | Chol neighbour 2 (distance) | Chol neighbour 3 (distance) | 3NN-mean (=imputed value)
--        | --                            | --                        | --                            |-- 
50 | 197.79 (0) | 201.33 (0.048) | 201.03 (0.048) | __200.05__ 
72 | 148.67 (0.184) | 157.83 (0.49) | 158.3 (0.525) | __154.93__ 
182 | 231.35 (0) | 227.75 (0.048) | 228.72 (0.083) | __229.27__ 


To further evaluate our kNN algorithm, we compared it against naive mean imputation on a second dataset. This dataset consisted of 1000 generated observations of patients with variables age, sex, height, weight and blood pressure. Values were generated with weak associations between different variables, i.e. blood pressure being higher for patients with larger values for height or weight.
Roughly 20% of blood pressure values were removed and imputed with the two methods to be compared.
In two separate iterations, both imputation methods were used to predict generated MCAR (missing completely at random) and MNAR (missing not at random) values. Accuracy was evaluated using the RMSE (Root Mean Squared Error) between predicted and actual values saved in a backup vector. 
For both MCAR and MNAR values, our kNN algorithm produced smaller RMSE (1.43 and 1.72 respectively) than naive mean imputation (2.38 and 3.22 respectively). Visually comparing kNN predictions and naive mean predictions to the actual values showed that kNN imputation was also fairly accurate for high and low values while naive mean imputation showed high discrepancy for very high and very low values.  

```{r, echo=FALSE, out.width="50%"}
include_graphics(path=c("img/knnMCAR.png", "img/meanMCAR.png"))
include_graphics(path=c("img/knnMNAR.png", "img/meanMNAR.png"))
```

## Simulations

In order to implement Survival Analysis, we decided to simulate specific variables for 11 additional points in time, resulting in 12 total values with steps being interpreted as months. Modeled variables included patient weight, BMI, tumour size and bilirubin. As cancer patients tend to lose weight over time, weight (and therefore BMI) were modeled to slightly decrease (normal distribution with $\mu =-0.6$ and $\sigma=0.5$ kg) with each month. 
For tumour size, we decided that both an increase and decrease over time should be possible with a growing tumour being more likely. Tumour size was modeled to be size of the previous month plus a uniformly randomly generated value between -0.01 and 0.05. 
Bilirubin was updated based on its previous values as well as tumour size for the patient, with tumour growth also implying an increase in bilirubin level.
Based on these simulations, we computed mortality probabilities for each patient and month. Mortality probability increased with:

 * high age
 * large tumour size
 * high bilirubin levels
 * high alcohol consumption
 * high number of packyears
 * diabetes
 
In addition, as it is common in longitudinal studies for patients to drop out of the study, either due to withdrawal or medical reasons, we calculated a censorship probability for each patient and month. We decided that patients with large tumour size, high BMI or high bilirubin levels should be more likely to be censored, as these patients may potentially need to undergo a different treatment.  
Afterwards, we used the mortality and censorship probabilities to generate a dataset containing information about whether patients are alive, dead or censored for each month. Once a patient had either died or been censored, all of the remaining months were also marked as dead or censored, respectively. 
After applying our approach, we ended up with 166 alive, 76 dead and 58 censored patients in month 12, values that we deemed acceptable for liver cancer.

## Packages For Dataset Manipulation

 * papeR (version 1.0-5, 2021-03-19)
 * dplyr (version 1.0.5)

# App Implementation

Throughout our project we went through different phases and reworked our design and structure several times. We used multiple libraries in our application.  

These are:

 * shiny (version 1.6.0)
 * tidyverse (version 1.3.1)
 * ggplot2 (version 3.3.3)
 * survminer (version 0.4.9)
 * gmodels (version 2.18.1)
 * knitr (version 1.28)
 * plotly (version 4.9.4.1)
 * gt (version 0.3.0)
 * papeR (version 1.0-5)
 * shinythemes (version 1.2.0)
 * survival (version 3.1-12)

We decided right away that we want to set up our application with the _navbarPage_ Layout, combined with tab panels. For visual reasons we decided to include a dark _shinytheme_. During the project we implemented six tabs in total. In the first one called _About App_, the team members and the GitHub link is displayed. In the second tab _About liver cancer_, one can find some information about our chosen type of cancer, implemented through an R Markdown file. The third one is called _Dataset_, where an interactive table of our manipulated dataset is displayed. The fourth one is called _Graphs_ and shows a Scatterplot, a Boxplot and a Histogram, all of which were implemented to be fully interactive. Our fifth tab _Tables_, contains a summary, frequency, risk and confidence interval table, all four were implemented completely interactive as well. The sixth and last tab consists of two parts. In the first part we implemented a Kaplan-Meier-Curve and in the second part an interactive plot, which displays the simulated variable for the given patient Id, both selected by the user.  
Firstly, we went for fluid rows and columns in the _Graphs_ and _Tables_ tabs, but later decided that a sidebar Layout would suit the app better, look cleaner as well as enabling larger plot outputs. We chose a global file to load all our libraries needed, as well as all the required checkbox and drop-down menu items and referenced it as a source in the _Server_ file. We did so to create a cleaner view and make the code more structured as well as to have a central place for all those chunks of code and save code duplications.  
To implement user interactivity, we chose to use selectinputs for our graphs and tables as well as checkboxes for our dataset tab. In order to avoid outputs without meaningful content, we limited selectable input options. For instance scatterplot does not make sense for non-metric variables.  
For our information tab about our chosen type of cancer, we managed to include an R-Markdown file and referenced it in the _ui_ file, also for the aforementioned purposes.  
To keep our structural integrity, we decided to implement the _server_ file wherever possible with _reactives_. On one hand this was done to keep the clean structure and on the other hand to increase the performance of our interactive elements, as they now only reload and recalculate in case of a change in specific input, instead of every time any change on that respective tab is made.  
The aforementioned libraries were used on different outputs for graphs and tables. For instance the scatterplot was implemented with the _plotly_ output to enable zooming in and out as well as other features for the user.  
The _gt_ package was used to create the frequency and risk tables. Both mostly for reasons of labeling and proper visualisation as the package grants the option of customising according to our preferences. The usage of the _survival_ and the _survminer_ packages was needed in order to implement our additional Survival Analysis content, as explained in the following section _Problems and Solutions_. 
All our plots were created with the _ggplot2_ package from the _tidyverse_. Only their output varies as mentioned above. 

# Problems and Solutions

During coding, we encountered many issues. Most of these issues were related to our table and plot outputs. Most prominently, our risk table did not work as we would have wanted it to. As our risk table was supposed to not only display a contingency table, but also compute risks, odds, risk difference, relative risk and odds ratio estimates, we were unable to use basic R functions. To solve this problem, we used the _gt_ package (see App Implementation) which allowed us to customise table output and most importantly assign labels to rows and columns. 
Another problem that we encountered had to do with variable labels in plot outputs. As some of our variable names were not perfectly intuitive (e.g. _alc_, _bili_, _hbv_), we wanted to assign labels to these variables for improved readability. To do this, we had to use package _papeR_'s (see Dataset Manipulation) _labels_ function to assign and retrieve variable labels. 
In our dataset tab, we had some trouble with implementing the "Select all" checkbox. Our plan was that this checkbox should be set to false (unchecked) if a variable gets deselected. This worked, but the deselected variable gets reselected immediately afterwards and the according checkbox has to be clicked once more. The issue can be circumvented by deselecting "Select all" first and then deselecting variables. 
When implementing our additional Survival Analysis content, we ran into multiple issues with the simulated datasets and plot output. Our used package _survminer_ (see App Implementation) required the dataset to be arranged in a specific way in order to draw the Kaplan-Meier-curve. _ggsurvplot_, the function used to draw the curve, requires a fit, an object consisting of patient survival time and information about occurrence of events. For this, we had to create a new dataframe including information about the aforementioned variables.  
Plot output of the survival curve did not work at first because we had incompatible output types in our server and ui scripts. Adjusting the output types accordingly fixed this problem.
Another issue we noticed after our presentation was the fact that simulated tumour size had not been removed accordingly for dead or censored patients after their respective event. As the presentation had already been held at this point in time, we could no longer fix this issue.

# Conclusion and Lessons Learned

In conclusion, the project was a great opportunity for us to work with R Shiny and program our own app. Practical experience from the lecture with other packages such as _dplyr_, _ggplot2_ was greatly beneficial for implementation. 
Most of our set goals for the app were achieved with the exception of pie charts and further statistical analysis (e.g. confounding). Additional implemented aspects were a dataset tab displaying our (manipulated) dataset as well as a table printing frequencies for two selected categorical variables. With plots and tables being customisable, user interactivity was achieved to our satisfaction.  
Besides the structure of Shiny Apps, we also learned about more advanced methods such as using a global script as well as adding R Markdown files to an app.
In terms of project difficulty, our team was very happy about the fact that we were able to expand on the app with our own ideas. 
As our team worked via the version control system Git, additional experience in this field was also gathered.

\pagebreak

# Individual Contributions

## Lars Andersen

The whole project was programmed and thought out as a team, except some minor exceptions at the end of the project. In the last phase of the project I was responsible for adding and implementing an R Markdown file, containing the information about our chosen cancer type as well as outsourcing our code which was used on multiple occacions in a global R script. Other minor tasks were script cleaning and displaying the boxplot grouping variable by colour in the plot.

## Morten Dreher

With only few exceptions towards the end of the project, the majority of the project was programmed with all team members being present and giving input. 
I was responsible for setting up and maintaining our team's Git repository.
In the final stages of the project, I reworked our risk table using the gt package, fixed some aspects of our Kaplan-Meier-curve and added labels to our data frame columns using the papeR package.
Other minor changes included fixing plot labels, correcting BMI computation and cleaning of scripts.

## Melita Coneva

To make the Shiny App more pleasant to look at, I could get creative and was responsible for the design. This included changing the theme for the navbarPage and the graphs, adding icons to the TabPanels and minor colour changes in our graphs.

# Sources 

 * https://pubmed.ncbi.nlm.nih.gov/20563664/
 * https://www.cdc.gov/tobacco/data_statistics/fact_sheets/youth_data/tobacco_use/
 * https://bookdown.org/yihui/rmarkdown/
 * https://shiny.rstudio.com/articles/reactivity-overview.html
 * https://style.tidyverse.org/
 * https://gt.rstudio.com/
 * https://plotly.com/r/
 * http://rpkgs.datanovia.com/survminer/reference/ggsurvplot.html
 
\pagebreak

# Appendix

```{r, echo=FALSE, out.width="100%"}
include_graphics("img/overview.png")
```
```{r, echo=FALSE, out.width="50%"}
include_graphics(path=c("img/aboutLiverCancer.png", "img/tables.png"))
include_graphics(path=c("img/graphs1.png", "img/graphs2.png"))
```
```{r, echo=FALSE, out.width="100%"}
include_graphics("img/graphs3.png")
```
```{r, echo=FALSE, out.width="100%"}
include_graphics(path=c("img/survivalAnalysis.png", "img/survivalAnalysis2.png"))
```